2019-11-23 00:15:37.182231
 + Exec time : 25.539378881454468
 + number of files : 15
    tf            idf
Python.: 0.019355      2.014903
release,: 0.006452      2.708050
tools: 0.038710      1.098612
broad: 0.006452      2.708050
investigation: 0.006452      2.708050
training,: 0.012903      2.014903
loading,: 0.012903      2.014903
common: 0.025806      1.609438
believe: 0.012903      2.014903
like: 0.025806      1.321756
step: 0.012903      2.014903
equipping: 0.006452      2.708050
out: 0.025806      1.321756
book,: 0.012903      2.708050
solve: 0.019355      1.609438
realistic: 0.006452      2.708050
resource: 0.006452      2.708050
developers: 0.012903      2.014903
but: 0.045161      0.916291
gradients,: 0.006452      2.708050
where: 0.025806      1.321756
current: 0.012903      2.014903
systems: 0.006452      2.708050
category: 0.006452      2.708050
input: 0.012903      2.014903
resulting: 0.012903      2.014903
downstream: 0.006452      2.708050
produce: 0.012903      2.014903
data.: 0.019355      1.609438
zeros: 0.006452      2.708050
set: 0.025806      1.609438
particularly: 0.006452      2.708050
other: 0.038710      1.098612
raw: 0.006452      2.708050
task: 0.006452      2.708050
labels.: 0.006452      2.708050
led: 0.006452      2.708050
compile: 0.006452      2.708050
static: 0.032258      1.609438
graph: 0.109677      1.321756
performance: 0.025806      1.609438
immediate: 0.019355      1.609438
regarding: 0.006452      2.708050
teaching: 0.006452      2.708050
*: 0.006452      2.708050
: 0.051613      1.321756
tweak: 0.006452      2.708050
Backpropagation: 0.006452      2.708050
(among: 0.006452      2.708050
things).: 0.006452      2.708050
hand.: 0.006452      2.708050
placeholders: 0.012903      2.708050
engine: 0.006452      2.708050
notion: 0.006452      2.708050
capa-: 0.006452      2.708050
improved: 0.006452      2.708050
wrapping: 0.006452      2.708050
CNTK: 0.006452      2.708050
DL4J,: 0.006452      2.708050
development.: 0.006452      2.708050
CUDA3,: 0.006452      2.708050
peek: 0.006452      2.708050
results: 0.019355      1.609438
willing: 0.012903      2.014903
backpropagation.: 0.006452      2.708050
autograd-enabled: 0.006452      2.708050
networks,: 0.006452      2.708050
correct:: 0.006452      2.708050
here.: 0.006452      2.708050
These: 0.019355      1.609438
production: 0.012903      2.014903
work: 0.006452      2.708050
Dataset,: 0.006452      2.708050
format: 0.006452      2.708050
waiting: 0.006452      2.708050
start: 0.012903      2.014903
When: 0.012903      2.014903
starts: 0.006452      2.708050
opportunity: 0.012903      2.708050
independently: 0.012903      2.708050
(JIT): 0.006452      2.708050
book: 0.012903      2.014903
(GPU),: 0.006452      2.708050
(we: 0.006452      2.708050
(and: 0.006452      2.708050
50: 0.006452      2.708050
updates: 0.006452      2.708050
good: 0.012903      2.014903
interesting: 0.006452      2.708050
Last: 0.006452      2.708050
command: 0.006452      2.708050
installation: 0.006452      2.708050
guide: 0.006452      2.708050
compatible: 0.006452      2.708050
item: 0.006452      2.708050
Markdown-formatted: 0.006452      2.708050
GitHub.8: 0.006452      2.708050
flexibility: 0.012903      2.014903
allows: 0.019355      1.609438
early: 0.006452      2.708050
range: 0.019355      1.609438
NumPy: 0.012903      2.014903
features: 0.038710      1.321756
train: 0.032258      1.321756
efficient: 0.012903      2.014903
you: 0.135484      0.510826
learn.: 0.006452      2.708050
need: 0.058065      0.916291
experience: 0.006452      2.708050
us.: 0.006452      2.708050
space.: 0.006452      2.708050
aim: 0.006452      2.708050
hosted: 0.006452      2.708050
games,: 0.006452      2.708050
examples.: 0.006452      2.708050
trained: 0.012903      2.014903
caveats: 0.006452      2.708050
automatic: 0.019355      1.609438
which: 0.096774      0.762140
pretend: 0.006452      2.708050
context: 0.006452      2.708050
fits: 0.006452      2.708050
zero,: 0.006452      2.708050
hand,: 0.006452      2.708050
by: 0.109677      0.510826
recorded: 0.006452      2.708050
byte: 0.006452      2.708050
standard: 0.038710      1.098612
implemented: 0.006452      2.708050
among: 0.006452      2.708050
deferred-execution: 0.012903      2.014903
strung: 0.006452      2.708050
keep: 0.012903      2.014903
differentiation: 0.012903      2.014903
bolically: 0.006452      2.708050
fifth: 0.006452      2.708050
Graph: 0.006452      2.708050
1.0.: 0.006452      2.708050
greedily: 0.006452      2.708050
interconnection: 0.006452      2.708050
still: 0.006452      2.708050
without: 0.006452      2.708050
through: 0.025806      1.321756
production.: 0.025806      1.609438
mode,”: 0.006452      2.708050
flawed,: 0.006452      2.708050
seems: 0.006452      2.708050
marked: 0.006452      2.708050
libraries,: 0.006452      2.708050
consolidation: 0.006452      2.708050
Lasagne: 0.006452      2.708050
various: 0.012903      2.014903
main: 0.019355      2.014903
lot: 0.012903      2.014903
reliable: 0.006452      2.708050
time,: 0.006452      2.708050
Depending: 0.006452      2.708050
scale,: 0.006452      2.708050
wider: 0.012903      2.014903
mental: 0.006452      2.708050
require: 0.019355      2.014903
thing: 0.006452      2.708050
track: 0.006452      2.708050
modules: 0.006452      2.708050
might: 0.006452      2.708050
specified: 0.006452      2.708050
implementation.: 0.012903      2.708050
cost: 0.019355      2.708050
implementation: 0.006452      2.708050
TorchScript,: 0.006452      2.708050
capabilities: 0.012903      2.014903
recent: 0.006452      2.708050
retraining: 0.006452      2.708050
quota.: 0.006452      2.708050
Linux: 0.006452      2.708050
whenever: 0.006452      2.708050
information,: 0.006452      2.708050
please: 0.006452      2.708050
variety: 0.006452      2.708050
working.: 0.006452      2.708050
kernel,: 0.012903      2.708050
rendered: 0.006452      2.708050
maintains: 0.006452      2.708050
menu: 0.006452      2.708050
evaluations,: 0.006452      2.708050
interactive: 0.006452      2.708050
questions,: 0.006452      2.708050
powerful: 0.006452      2.708050
fit: 0.006452      2.708050
facilitates: 0.006452      2.708050
use: 0.077419      0.405465
laundry: 0.006452      2.708050
Tensors: 0.006452      2.708050
processes: 0.012903      2.014903
Though: 0.006452      2.708050
we: 0.090323      0.510826
accessible: 0.006452      2.708050
than: 0.032258      1.321756
this: 0.103226      0.310155
programming: 0.006452      2.708050
examples: 0.019355      1.609438
allow: 0.012903      2.014903
at: 0.058065      0.628609
specific: 0.019355      1.609438
amounts: 0.006452      2.708050
look: 0.012903      2.014903
debug.: 0.006452      2.708050
although: 0.006452      2.708050
starting: 0.012903      2.014903
Until: 0.006452      2.708050
late: 0.006452      2.708050
2000s,: 0.006452      2.708050
“machine: 0.006452      2.708050
classifier,: 0.006452      2.708050
representations: 0.032258      2.708050
filters: 0.012903      2.708050
direction: 0.006452      2.708050
edge: 0.006452      2.708050
useful: 0.012903      2.708050
automatically,: 0.012903      2.014903
refined: 0.012903      2.014903
basis: 0.012903      2.014903
powerful.: 0.006452      2.708050
handcrafting: 0.006452      2.708050
these: 0.032258      1.321756
created: 0.012903      2.014903
adding,: 0.006452      2.708050
square: 0.006452      2.708050
expression: 0.025806      1.609438
basic: 0.006452      2.708050
math: 0.012903      2.014903
understand: 0.006452      2.708050
execution: 0.038710      1.609438
fundamental: 0.012903      2.014903
row: 0.006452      2.708050
mind:: 0.006452      2.708050
output: 0.025806      1.609438
writing: 0.006452      2.708050
row): 0.006452      2.708050
case,: 0.019355      1.609438
w,: 0.006452      2.708050
similar: 0.012903      2.708050
default: 0.012903      2.014903
sports: 0.006452      2.708050
expressions,: 0.006452      2.708050
January: 0.006452      2.708050
low-level: 0.006452      2.708050
around: 0.006452      2.708050
adoption: 0.006452      2.708050
C++: 0.019355      2.014903
physics,: 0.006452      2.708050
needed: 0.012903      2.708050
networks: 0.012903      2.014903
layers: 0.006452      2.708050
functions: 0.006452      2.708050
project,: 0.006452      2.708050
acts: 0.006452      2.708050
minute,: 0.006452      2.708050
completing: 0.006452      2.708050
full: 0.012903      2.014903
individually,: 0.006452      2.708050
sets: 0.006452      2.708050
equipped: 0.012903      2.014903
University: 0.006452      2.708050
(OS).: 0.006452      2.708050
Windows: 0.012903      2.708050
possible: 0.006452      2.708050
install: 0.012903      2.708050
course,: 0.006452      2.708050
preferred: 0.006452      2.708050
development: 0.006452      2.708050
state: 0.006452      2.708050
ask: 0.006452      2.708050
friction: 0.006452      2.708050
emphasizes: 0.006452      2.708050
since: 0.006452      2.708050
data: 0.135484      0.628609
list: 0.019355      1.609438
built: 0.025806      1.609438
get: 0.025806      1.609438
usable: 0.006452      2.708050
contexts: 0.006452      2.708050
also: 0.032258      1.321756
going: 0.025806      1.609438
like.: 0.006452      2.708050
your: 0.058065      0.916291
much: 0.012903      2.014903
Deep: 0.012903      2.014903
problems: 0.006452      2.708050
tasks—such: 0.006452      2.708050
translation,: 0.006452      2.708050
cluttered: 0.006452      2.708050
so: 0.064516      0.916291
flexible: 0.006452      2.708050
reasons: 0.006452      2.708050
because: 0.012903      2.014903
learn,: 0.006452      2.708050
practices,: 0.006452      2.708050
GPU: 0.032258      1.321756
forward: 0.006452      2.708050
those: 0.045161      0.916291
exist: 0.006452      2.708050
fell: 0.006452      2.708050
numerical: 0.006452      2.708050
Feature: 0.006452      2.708050
problem.: 0.006452      2.708050
you’d: 0.006452      2.708050
edges: 0.006452      2.708050
digit,: 0.006452      2.708050
loopy: 0.006452      2.708050
data,: 0.038710      1.609438
often: 0.019355      1.609438
better: 0.006452      2.708050
technologies,: 0.006452      2.708050
fact: 0.012903      2.014903
Often: 0.006452      2.708050
libraries: 0.025806      1.321756
about: 0.012903      2.014903
well: 0.006452      2.708050
flow: 0.006452      2.708050
won’t: 0.006452      2.708050
lays: 0.006452      2.708050
parameters: 0.025806      2.014903
desire),: 0.006452      2.708050
backpropagation: 0.006452      2.708050
saving: 0.006452      2.708050
node: 0.019355      2.014903
(second: 0.006452      2.708050
differentiation,: 0.006452      2.708050
traverses: 0.006452      2.708050
row.: 0.006452      2.708050
By: 0.012903      2.014903
running: 0.045161      1.098612
encountered.: 0.006452      2.708050
achieved: 0.006452      2.708050
outputs: 0.006452      2.708050
converging: 0.006452      2.708050
API,: 0.012903      2.014903
wrappers,: 0.006452      2.708050
beta: 0.006452      2.708050
Torch: 0.006452      2.708050
roughly: 0.006452      2.708050
map: 0.006452      2.708050
ways: 0.019355      2.014903
pure-Python: 0.006452      2.708050
viable: 0.006452      2.708050
core,: 0.006452      2.708050
called: 0.006452      2.708050
tensors: 0.032258      2.708050
Both: 0.006452      2.708050
two.: 0.006452      2.708050
argue: 0.012903      2.014903
on.: 0.006452      2.708050
being: 0.019355      1.609438
located: 0.006452      2.708050
structure: 0.006452      2.708050
whatever: 0.006452      2.708050
soon: 0.006452      2.708050
simplest: 0.006452      2.708050
common,: 0.006452      2.708050
torch.distributed: 0.006452      2.708050
bypass: 0.006452      2.708050
gives: 0.006452      2.708050
Hardware: 0.006452      2.708050
least: 0.006452      2.708050
faster).: 0.006452      2.708050
Taken: 0.006452      2.708050
If: 0.012903      2.014903
Otherwise,: 0.006452      2.708050
preinstalled,: 0.006452      2.708050
supported: 0.006452      2.708050
avoid: 0.006452      2.708050
OS;: 0.006452      2.708050
website.5: 0.006452      2.708050
Miniconda.: 0.006452      2.708050
environments.: 0.006452      2.708050
restarted.: 0.006452      2.708050
box: 0.006452      2.708050
important: 0.006452      2.708050
cognitive: 0.006452      2.708050
in: 0.361290      0.068993
years: 0.012903      2.014903
prominent: 0.006452      2.708050
provides: 0.045161      1.321756
was: 0.006452      2.708050
design: 0.006452      2.708050
network: 0.051613      0.916291
(assuming: 0.006452      2.708050
worker: 0.006452      2.708050
we’ll: 0.019355      1.609438
exposing: 0.006452      2.708050
do: 0.006452      2.708050
efficient,: 0.006452      2.708050
additional: 0.019355      1.609438
until: 0.012903      2.014903
arises.: 0.006452      2.708050
algorithm,: 0.006452      2.708050
engineering: 0.012903      2.708050
tell: 0.006452      2.708050
digits,: 0.006452      2.708050
deals: 0.006452      2.708050
entity: 0.006452      2.708050
disruptive: 0.006452      2.708050
issues: 0.006452      2.708050
networks.: 0.012903      2.014903
concepts: 0.012903      2.708050
groundwork: 0.006452      2.708050
block: 0.006452      2.708050
b: 0.006452      2.708050
needed.: 0.006452      2.708050
One: 0.012903      2.014903
execution.: 0.006452      2.708050
engine.: 0.006452      2.708050
incrementally.: 0.006452      2.708050
conditions: 0.012903      2.708050
record: 0.006452      2.708050
goal: 0.006452      2.708050
competitive: 0.006452      2.708050
others: 0.006452      2.708050
followed,: 0.006452      2.708050
consolidated: 0.006452      2.708050
active: 0.006452      2.708050
put: 0.006452      2.708050
perfectly: 0.006452      2.708050
example.: 0.006452      2.708050
compared: 0.006452      2.708050
optimization,: 0.006452      2.708050
modeling,: 0.006452      2.708050
creative: 0.006452      2.708050
scientific: 0.006452      2.708050
foremost: 0.006452      2.708050
loss: 0.006452      2.708050
center: 0.006452      2.708050
loading: 0.006452      2.708050
Tensor.: 0.006452      2.708050
multiple: 0.032258      1.609438
(eager: 0.006452      2.708050
typically: 0.012903      2.014903
think: 0.012903      2.014903
sequences: 0.006452      2.708050
laptop: 0.012903      2.708050
suggest: 0.019355      2.014903
cuts: 0.006452      2.708050
40: 0.006452      2.708050
hours: 0.006452      2.708050
Stanford: 0.006452      2.708050
2018.: 0.006452      2.708050
options,: 0.006452      2.708050
verified: 0.006452      2.708050
making: 0.006452      2.708050
page: 0.012903      2.708050
cells: 0.012903      2.708050
value: 0.006452      2.708050
below: 0.006452      2.708050
cells,: 0.006452      2.708050
directory: 0.006452      2.708050
depends: 0.006452      2.708050
details: 0.006452      2.708050
everyone.: 0.012903      2.708050
different: 0.006452      2.708050
be: 0.238710      0.143101
the: 1.309677      0.000000
most: 0.032258      1.321756
appropriate: 0.006452      2.708050
software: 0.012903      2.014903
acquisition: 0.006452      2.708050
follow: 0.012903      2.014903
covering: 0.012903      2.708050
focus: 0.019355      1.609438
PyTorch,: 0.006452      2.708050
https://arxiv.org.1: 0.006452      2.708050
said,: 0.006452      2.708050
objects: 0.006452      2.708050
illustrative: 0.006452      2.708050
over: 0.032258      1.098612
You: 0.045161      0.916291
previously.: 0.006452      2.708050
expression.: 0.012903      2.014903
user: 0.006452      2.708050
classifier: 0.006452      2.708050
number: 0.006452      2.708050
system.: 0.006452      2.708050
usually: 0.019355      2.014903
languages: 0.006452      2.708050
between: 0.019355      1.609438
execution,: 0.012903      2.014903
tanh(w: 0.006452      2.708050
x: 0.012903      2.708050
each: 0.012903      2.708050
requires: 0.006452      2.708050
respect: 0.012903      2.014903
numerically: 0.006452      2.708050
row).: 0.006452      2.708050
competing: 0.006452      2.708050
evaluated.: 0.006452      2.708050
program: 0.006452      2.708050
traversing: 0.006452      2.708050
distinct: 0.006452      2.708050
approaches.: 0.006452      2.708050
gained: 0.019355      2.014903
“eager: 0.006452      2.708050
era: 0.006452      2.708050
well.: 0.006452      2.708050
dwindling: 0.006452      2.708050
ceased: 0.006452      2.708050
First,: 0.006452      2.708050
case’s: 0.006452      2.708050
torch: 0.006452      2.708050
derivatives: 0.006452      2.708050
having: 0.006452      2.708050
tensor: 0.012903      2.014903
build: 0.012903      2.708050
1.4: 0.012903      2.708050
setup: 0.006452      2.708050
optimizer: 0.006452      2.708050
Utilities: 0.006452      2.708050
handling: 0.006452      2.708050
torch.util.data.: 0.006452      2.708050
standardized: 0.006452      2.708050
load: 0.006452      2.708050
Dataset: 0.006452      2.708050
required: 0.012903      2.014903
immediately.: 0.006452      2.708050
interpreter: 0.006452      2.708050
transform: 0.006452      2.708050
hardware.: 0.006452      2.708050
order: 0.006452      2.708050
aimed: 0.006452      2.708050
GPU-enabled: 0.006452      2.708050
macOS: 0.012903      2.708050
Anaconda: 0.006452      2.708050
Linux,: 0.006452      2.708050
memory: 0.006452      2.708050
terminated: 0.006452      2.708050
plots.: 0.006452      2.708050
repository: 0.006452      2.708050
new: 0.058065      0.916291
accelerate: 0.006452      2.708050
providing: 0.019355      1.609438
way: 0.019355      1.609438
facilitate: 0.012903      2.014903
generation: 0.006452      2.708050
working: 0.012903      2.014903
knowledge: 0.012903      2.014903
backbone: 0.006452      2.708050
dirty—It’ll: 0.006452      2.708050
complicated: 0.012903      2.708050
occur: 0.006452      2.708050
decided: 0.006452      2.708050
recommend: 0.006452      2.708050
It’s: 0.012903      2.014903
class: 0.025806      1.609438
suitable: 0.006452      2.708050
backward: 0.012903      2.014903
pass: 0.006452      2.708050
feature: 0.019355      2.708050
Features: 0.006452      2.708050
transformations: 0.006452      2.708050
correct: 0.012903      2.708050
fed: 0.006452      2.708050
algorithm: 0.006452      2.708050
estimate: 0.006452      2.708050
looking: 0.006452      2.708050
inject: 0.006452      2.708050
form: 0.032258      1.098612
code.: 0.019355      1.609438
(such: 0.006452      2.708050
difficult,: 0.006452      2.708050
visibility: 0.006452      2.708050
depth: 0.006452      2.708050
instead: 0.006452      2.708050
Understanding: 0.006452      2.708050
though: 0.012903      2.014903
Neurons: 0.006452      2.708050
figure: 0.032258      1.609438
=: 0.006452      2.708050
via: 0.012903      2.014903
1.2,: 0.006452      2.708050
compiled: 0.012903      2.014903
evaluated: 0.019355      1.609438
multiplies: 0.006452      2.708050
gradients: 0.006452      2.708050
(fourth: 0.006452      2.708050
major: 0.012903      2.014903
TensorFlow,: 0.012903      2.014903
uses: 0.006452      2.708050
kind: 0.006452      2.708050
1.3: 0.006452      2.708050
computations.: 0.006452      2.708050
Automatic: 0.006452      2.708050
Explosion–like: 0.006452      2.708050
unification.: 0.006452      2.708050
lately: 0.006452      2.708050
niches: 0.006452      2.708050
hinted: 0.006452      2.708050
Now: 0.006452      2.708050
massive: 0.012903      2.708050
models,: 0.006452      2.708050
them,: 0.006452      2.708050
term: 0.006452      2.708050
integration: 0.006452      2.708050
CPU: 0.019355      2.014903
performed: 0.006452      2.708050
further: 0.012903      2.014903
likely: 0.006452      2.708050
But: 0.012903      2.014903
convolutional: 0.006452      2.708050
it’s: 0.025806      1.321756
ready: 0.012903      2.014903
1070: 0.006452      2.708050
mandatory: 0.006452      2.708050
scratch: 0.006452      2.708050
clusters: 0.006452      2.708050
cloud: 0.019355      2.708050
support: 0.012903      2.708050
systems,: 0.006452      2.708050
cell,: 0.006452      2.708050
read: 0.006452      2.708050
looks: 0.006452      2.708050
overhead,: 0.006452      2.708050
Use: 0.006452      2.708050
deep: 0.161290      0.405465
found: 0.019355      2.014903
adopters: 0.006452      2.708050
library’s: 0.012903      2.014903
core: 0.019355      1.609438
extensive: 0.012903      2.014903
on: 0.283871      0.405465
numbers,: 0.006452      2.708050
if: 0.025806      1.609438
we’ve: 0.006452      2.708050
strategy: 0.012903      2.014903
can: 0.193548      0.510826
problem: 0.006452      2.708050
inputs.: 0.006452      2.708050
find: 0.012903      2.014903
automatically: 0.012903      2.014903
mostly: 0.006452      2.708050
outcomes: 0.006452      2.708050
original: 0.006452      2.708050
come: 0.012903      2.708050
ones: 0.006452      2.708050
handwritten: 0.006452      2.708050
given: 0.012903      2.014903
holes: 0.006452      2.708050
target: 0.006452      2.708050
place: 0.012903      2.014903
function: 0.012903      2.014903
taking: 0.006452      2.708050
(a: 0.006452      2.708050
debugging: 0.012903      2.708050
intermediate: 0.006452      2.708050
top: 0.012903      2.014903
frameworks,: 0.012903      2.014903
see: 0.032258      1.098612
o: 0.006452      2.708050
explain: 0.006452      2.708050
figures,: 0.006452      2.708050
compute: 0.019355      1.609438
outputs.: 0.006452      2.708050
plugged: 0.006452      2.708050
calculation: 0.006452      2.708050
construction: 0.006452      2.708050
graphs.: 0.006452      2.708050
represented: 0.006452      2.708050
language,: 0.006452      2.708050
increasing: 0.006452      2.708050
all: 0.019355      2.014903
release: 0.019355      2.014903
transition: 0.006452      2.708050
exchange: 0.006452      2.708050
libraries.: 0.006452      2.708050
Keras: 0.012903      2.708050
ecosystem.: 0.012903      2.014903
filling: 0.006452      2.708050
Py: 0.006452      2.708050
Python,: 0.019355      2.014903
non-Python: 0.006452      2.708050
NVIDIA: 0.019355      2.014903
There: 0.006452      2.708050
Indeed,: 0.006452      2.708050
provided: 0.012903      2.708050
second: 0.012903      2.014903
components.: 0.006452      2.708050
functions,: 0.006452      2.708050
adapt: 0.006452      2.708050
want: 0.006452      2.708050
machines: 0.012903      2.014903
torch.nn.DataParallel: 0.006452      2.708050
employed: 0.006452      2.708050
resemble: 0.006452      2.708050
side,: 0.006452      2.708050
offer: 0.012903      2.014903
virtual: 0.006452      2.708050
pretrained: 0.012903      2.708050
unit: 0.012903      2.014903
error.: 0.006452      2.708050
reduced: 0.006452      2.708050
setups: 0.006452      2.708050
prohibitive: 0.006452      2.708050
benchmarks: 0.006452      2.708050
great.: 0.006452      2.708050
checking: 0.006452      2.708050
system: 0.012903      2.014903
CUDA,: 0.006452      2.708050
assuming: 0.006452      2.708050
scripts’: 0.006452      2.708050
Notebook.: 0.006452      2.708050
Other: 0.006452      2.708050
Notebooks: 0.025806      2.014903
example: 0.006452      2.708050
variables: 0.012903      2.708050
evaluation: 0.006452      2.708050
evaluate: 0.006452      2.708050
(by: 0.006452      2.708050
pressing: 0.006452      2.708050
up,: 0.006452      2.708050
files.: 0.006452      2.708050
ideas: 0.006452      2.708050
What: 0.006452      2.708050
PyTorch?: 0.012903      2.014903
library: 0.045161      1.321756
learning: 0.167742      0.405465
of: 0.722581      0.000000
research: 0.019355      2.014903
Tensor,: 0.006452      2.708050
arrays.: 0.006452      2.708050
foundation,: 0.006452      2.708050
hardware: 0.045161      1.321756
an: 0.096774      0.510826
excellent: 0.006452      2.708050
introduction: 0.019355      1.609438
decision: 0.006452      2.708050
technical: 0.006452      2.708050
during: 0.032258      1.098612
decades: 0.006452      2.708050
two: 0.019355      1.609438
floating-point: 0.006452      2.708050
space—specifically,: 0.006452      2.708050
using: 0.045161      1.098612
ArXiV: 0.006452      2.708050
machine: 0.025806      1.321756
are: 0.180645      0.143101
presence: 0.006452      2.708050
why: 0.006452      2.708050
Tensor: 0.012903      2.708050
acceleration: 0.006452      2.708050
free: 0.025806      1.609438
them: 0.019355      2.014903
revolution: 0.006452      2.708050
provide: 0.006452      2.708050
landscape: 0.025806      2.014903
broader: 0.006452      2.708050
distribution: 0.006452      2.708050
Another: 0.006452      2.708050
would: 0.012903      2.014903
learning;: 0.006452      2.708050
however,: 0.025806      1.321756
definition,: 0.006452      2.708050
b,: 0.006452      2.708050
reasons).: 0.006452      2.708050
exceptions: 0.006452      2.708050
host: 0.006452      2.708050
case).: 0.006452      2.708050
numbers: 0.019355      2.708050
modes: 0.012903      2.014903
single-neuron: 0.006452      2.708050
(to: 0.006452      2.708050
trouble: 0.006452      2.708050
when: 0.012903      2.014903
stored: 0.006452      2.708050
TensorFlow: 0.032258      2.014903
behind-thescenes: 0.006452      2.708050
operations,: 0.006452      2.708050
operation.: 0.006452      2.708050
putting: 0.006452      2.708050
2017: 0.006452      2.708050
Theano,: 0.012903      2.708050
components: 0.019355      2.014903
shines: 0.006452      2.708050
pay: 0.006452      2.708050
blocks: 0.006452      2.708050
Figure: 0.012903      2.708050
deploys: 0.006452      2.708050
Fully: 0.006452      2.708050
activation: 0.006452      2.708050
initialize: 0.006452      2.708050
Basic: 0.006452      2.708050
bridge: 0.006452      2.708050
earlier,: 0.006452      2.708050
process: 0.012903      2.014903
runtime,: 0.006452      2.708050
incurring: 0.006452      2.708050
computer.: 0.006452      2.708050
laptop.: 0.006452      2.708050
adjusted: 0.006452      2.708050
magnitude: 0.006452      2.708050
parameter: 0.006452      2.708050
involves: 0.006452      2.708050
large,: 0.006452      2.708050
execute: 0.006452      2.708050
send: 0.006452      2.708050
page.: 0.006452      2.708050
code,: 0.012903      2.708050
everything: 0.006452      2.708050
feel: 0.006452      2.708050
investigating: 0.006452      2.708050
a: 0.716129      0.000000
that: 0.335484      0.000000
has: 0.116129      0.405465
structure,: 0.006452      2.708050
many: 0.032258      1.098612
packages: 0.019355      2.014903
functions.: 0.006452      2.708050
As: 0.038710      1.098612
tool: 0.006452      2.708050
Whether: 0.006452      2.708050
Some: 0.006452      2.708050
pull: 0.006452      2.708050
you’ll: 0.032258      1.321756
hands: 0.006452      2.708050
learn: 0.006452      2.708050
Most: 0.012903      2.014903
processing: 0.012903      2.014903
great: 0.006452      2.708050
scenes—by: 0.006452      2.708050
PyTorch.: 0.038710      1.321756
extend,: 0.006452      2.708050
who: 0.012903      2.708050
NumPy,: 0.006452      2.708050
makes: 0.019355      1.609438
such: 0.064516      0.762140
don’t: 0.025806      1.609438
then: 0.019355      1.609438
handcrafted!: 0.006452      2.708050
compiling: 0.006452      2.708050
directly: 0.012903      2.014903
wrong: 0.006452      2.708050
Also,: 0.006452      2.708050
domain-specific: 0.006452      2.708050
Next,: 0.012903      2.014903
how: 0.012903      2.014903
b).: 0.006452      2.708050
matches: 0.006452      2.708050
calculations: 0.019355      1.609438
symbolic: 0.006452      2.708050
contrast,: 0.006452      2.708050
advance: 0.006452      2.708050
precompiled: 0.012903      2.014903
Theano: 0.006452      2.708050
Dynet,: 0.006452      2.708050
largely: 0.006452      2.708050
few: 0.019355      1.609438
written: 0.006452      2.708050
parallelism: 0.006452      2.708050
Running: 0.012903      2.014903
so,: 0.006452      2.708050
model,: 0.012903      2.708050
torch.nn,: 0.006452      2.708050
architectural: 0.006452      2.708050
deployment: 0.012903      2.014903
classes: 0.006452      2.708050
custom: 0.006452      2.708050
DataLoader,: 0.006452      2.708050
spawn: 0.006452      2.708050
GPUs: 0.019355      2.014903
their: 0.012903      2.014903
Whenever: 0.006452      2.708050
calling: 0.012903      2.708050
up.: 0.006452      2.708050
Using: 0.012903      2.014903
serialize: 0.006452      2.708050
costs: 0.012903      2.014903
fused: 0.006452      2.708050
Even: 0.006452      2.708050
specialize: 0.006452      2.708050
clear:: 0.006452      2.708050
around,: 0.006452      2.708050
workable: 0.006452      2.708050
Pip: 0.006452      2.708050
that’s: 0.012903      2.014903
Notebook: 0.006452      2.708050
notebook: 0.032258      2.014903
add: 0.006452      2.708050
earlier: 0.006452      2.708050
cells.: 0.006452      2.708050
cell: 0.012903      2.708050
text: 0.006452      2.708050
beautiful: 0.006452      2.708050
Jupyter.: 0.006452      2.708050
starts,: 0.006452      2.708050
pops: 0.006452      2.708050
listings: 0.006452      2.708050
programs: 0.006452      2.708050
mathematical: 0.025806      1.321756
professional: 0.006452      2.708050
stress: 0.006452      2.708050
skills.: 0.006452      2.708050
projects: 0.006452      2.708050
Willingness: 0.006452      2.708050
dive: 0.006452      2.708050
huge: 0.006452      2.708050
3D: 0.006452      2.708050
as: 0.154839      0.223144
publications: 0.006452      2.708050
public: 0.006452      2.708050
carry: 0.006452      2.708050
model: 0.096774      1.098612
large: 0.019355      1.609438
correctly: 0.006452      2.708050
take: 0.045161      1.098612
researchers: 0.006452      2.708050
use,: 0.006452      2.708050
(like: 0.006452      2.708050
domain): 0.006452      2.708050
feels: 0.012903      2.708050
arrays,: 0.012903      2.014903
engineering.: 0.006452      2.708050
example,: 0.019355      2.014903
eight,: 0.006452      2.708050
twos.: 0.006452      2.708050
extract: 0.006452      2.708050
perspective.: 0.006452      2.708050
point: 0.006452      2.708050
lack: 0.006452      2.708050
language: 0.012903      2.014903
here,: 0.006452      2.708050
network.: 0.006452      2.708050
weights: 0.025806      2.708050
update: 0.006452      2.708050
inputs: 0.012903      2.014903
Then: 0.006452      2.708050
evaluated,: 0.006452      2.708050
backward,: 0.006452      2.708050
discussed.: 0.006452      2.708050
0.1: 0.006452      2.708050
proliferation: 0.006452      2.708050
premiere: 0.006452      2.708050
PyTorch),: 0.006452      2.708050
run: 0.045161      1.098612
deploying: 0.006452      2.708050
interact: 0.012903      2.014903
problems.: 0.006452      2.708050
analytically: 0.006452      2.708050
1.4.: 0.006452      2.708050
things: 0.012903      2.014903
source: 0.012903      2.014903
in),: 0.006452      2.708050
leverage: 0.006452      2.708050
answers: 0.006452      2.708050
involving: 0.006452      2.708050
carried: 0.006452      2.708050
tensors,: 0.006452      2.708050
limited: 0.006452      2.708050
Just: 0.006452      2.708050
more-advanced: 0.006452      2.708050
GTX: 0.006452      2.708050
incrementally: 0.006452      2.708050
minimize: 0.006452      2.708050
Moderately: 0.006452      2.708050
publicly: 0.006452      2.708050
try: 0.006452      2.708050
convert: 0.006452      2.708050
readily.: 0.006452      2.708050
Started: 0.006452      2.708050
installed: 0.012903      2.014903
browser: 0.012903      2.014903
defined: 0.006452      2.708050
choosing: 0.006452      2.708050
Shift-Enter).: 0.006452      2.708050
line: 0.006452      2.708050
minimizing: 0.006452      2.708050
PyTorch: 0.283871      0.143101
for: 0.270968      0.068993
projects.: 0.012903      2.014903
models: 0.038710      1.321756
expressed: 0.006452      2.708050
This: 0.032258      1.321756
it: 0.109677      0.510826
multidimensional: 0.012903      2.014903
distributed: 0.006452      2.708050
programming,: 0.006452      2.708050
real-world,: 0.006452      2.708050
We: 0.058065      0.628609
wide: 0.012903      2.014903
will: 0.032258      1.098612
come.: 0.006452      2.708050
any: 0.038710      1.098612
classes,: 0.006452      2.708050
easier: 0.006452      2.708050
In: 0.051613      0.916291
explore: 0.006452      2.708050
literature.: 0.006452      2.708050
Why: 0.006452      2.708050
section,: 0.012903      2.014903
Many: 0.006452      2.708050
generally: 0.006452      2.708050
For: 0.025806      1.609438
immediately: 0.012903      2.014903
familiar.: 0.006452      2.708050
learning”: 0.006452      2.708050
images: 0.006452      2.708050
successfully.: 0.006452      2.708050
iteratively: 0.006452      2.708050
examples,: 0.006452      2.708050
what: 0.025806      1.321756
operating: 0.025806      1.609438
squaring: 0.006452      2.708050
operations): 0.006452      2.708050
advantage: 0.012903      2.014903
pure: 0.006452      2.708050
another: 0.006452      2.708050
states: 0.006452      2.708050
graphs: 0.006452      2.708050
mix: 0.006452      2.708050
they’re: 0.019355      1.609438
concrete: 0.012903      2.014903
types.: 0.006452      2.708050
neuron: 0.019355      2.708050
row),: 0.006452      2.708050
operation: 0.012903      2.014903
define-by-run: 0.012903      2.014903
half: 0.012903      2.708050
under: 0.006452      2.708050
does: 0.006452      2.708050
according: 0.006452      2.708050
itself—a: 0.006452      2.708050
been: 0.006452      2.708050
moving: 0.006452      2.708050
niches:: 0.006452      2.708050
included: 0.006452      2.708050
C.: 0.006452      2.708050
capability: 0.012903      2.708050
usability: 0.006452      2.708050
doing: 0.006452      2.708050
We’re: 0.019355      2.014903
across: 0.006452      2.708050
spectrum: 0.006452      2.708050
connected: 0.006452      2.708050
torch.optim: 0.006452      2.708050
mentioned: 0.006452      2.708050
instruction: 0.012903      2.708050
fast: 0.012903      2.014903
within: 0.006452      2.708050
8GB: 0.006452      2.708050
times: 0.006452      2.708050
(from: 0.006452      2.708050
fractions: 0.006452      2.708050
CPU.: 0.006452      2.708050
over,: 0.006452      2.708050
initiative: 0.006452      2.708050
available: 0.006452      2.708050
Jupyter: 0.045161      1.609438
lines: 0.006452      2.708050
users,: 0.006452      2.708050
assume: 0.006452      2.708050
inline: 0.006452      2.708050
returned: 0.006452      2.708050
printed: 0.006452      2.708050
documents.: 0.006452      2.708050
our: 0.019355      2.708050
Python: 0.096774      0.762140
It: 0.019355      1.609438
idiomatic: 0.006452      2.708050
applications.: 0.012903      2.014903
neural: 0.051613      0.916291
architecture.: 0.006452      2.708050
operations: 0.070968      0.762140
both: 0.019355      1.609438
high-level: 0.038710      1.098612
last: 0.012903      2.014903
leave: 0.006452      2.708050
toward: 0.012903      2.014903
one:: 0.006452      2.708050
types,: 0.006452      2.708050
ground: 0.006452      2.708050
latest: 0.006452      2.708050
related: 0.019355      1.609438
preprint: 0.006452      2.708050
repository,: 0.006452      2.708050
identifying: 0.006452      2.708050
adapted: 0.006452      2.708050
perform: 0.012903      2.014903
best: 0.006452      2.708050
have: 0.070968      0.762140
used: 0.038710      1.321756
relevant: 0.012903      2.014903
heavily: 0.006452      2.708050
learning,: 0.006452      2.708050
say: 0.006452      2.708050
no: 0.012903      2.014903
aren’t: 0.006452      2.708050
de-facto: 0.006452      2.708050
relationships: 0.012903      2.708050
even: 0.012903      2.014903
typical: 0.012903      2.014903
computation.: 0.006452      2.708050
changed: 0.012903      2.014903
closely: 0.012903      2.014903
accordingly.: 0.006452      2.708050
us: 0.006452      2.708050
individual: 0.025806      2.014903
mean: 0.006452      2.708050
invoked: 0.012903      2.014903
Cambrian: 0.006452      2.708050
formats: 0.006452      2.708050
quickly: 0.006452      2.708050
At: 0.019355      1.609438
PyTorch’s: 0.006452      2.708050
(the: 0.006452      2.708050
Lua-based: 0.006452      2.708050
community: 0.006452      2.708050
batteries: 0.006452      2.708050
already: 0.006452      2.708050
there’s: 0.006452      2.708050
reasons,: 0.006452      2.708050
GPUs.: 0.019355      1.609438
requirements: 0.006452      2.708050
library,: 0.012903      2.014903
such,: 0.006452      2.708050
loads: 0.006452      2.708050
trains: 0.006452      2.708050
untrained: 0.006452      2.708050
specialized: 0.012903      2.014903
mode).: 0.006452      2.708050
executed: 0.012903      2.708050
operate: 0.006452      2.708050
operations.: 0.012903      2.708050
Besides: 0.006452      2.708050
known: 0.006452      2.708050
graphical: 0.006452      2.708050
modern: 0.006452      2.708050
times,: 0.006452      2.708050
days: 0.006452      2.708050
real-world: 0.006452      2.708050
sound: 0.006452      2.708050
DAWNBench4: 0.006452      2.708050
tasks: 0.006452      2.708050
platforms,: 0.006452      2.708050
Because: 0.006452      2.708050
include: 0.006452      2.708050
CPU-only.: 0.006452      2.708050
particular: 0.006452      2.708050
official: 0.006452      2.708050
installers.: 0.006452      2.708050
Experienced: 0.006452      2.708050
results,: 0.006452      2.708050
type: 0.006452      2.708050
kernel: 0.006452      2.708050
goes: 0.006452      2.708050
checkout: 0.006452      2.708050
and: 0.580645      0.000000
to: 0.696774      0.000000
approachability: 0.006452      2.708050
grown: 0.006452      2.708050
From: 0.006452      2.708050
up: 0.032258      1.609438
should: 0.019355      2.014903
first: 0.038710      1.098612
you.: 0.006452      2.708050
scientists,: 0.006452      2.708050
practitioners: 0.019355      1.609438
from: 0.129032      0.310155
along: 0.012903      2.014903
part: 0.006452      2.708050
A: 0.019355      2.014903
performing: 0.012903      2.014903
Pythonic,: 0.006452      2.708050
calculating: 0.006452      2.708050
API: 0.012903      2.014903
tools.: 0.006452      2.708050
ability: 0.012903      2.014903
Often,: 0.006452      2.708050
Instead,: 0.006452      2.708050
code: 0.064516      0.916291
went: 0.006452      2.708050
deferred: 0.019355      1.609438
specifically: 0.006452      2.708050
giving: 0.006452      2.708050
concepts.: 0.006452      2.708050
neuron.: 0.006452      2.708050
1.2:: 0.006452      2.708050
+: 0.006452      2.708050
facts: 0.006452      2.708050
w: 0.006452      2.708050
error: 0.006452      2.708050
computing: 0.019355      2.014903
gradient: 0.012903      2.708050
gets: 0.012903      2.014903
represents: 0.006452      2.708050
(in: 0.012903      2.014903
values: 0.006452      2.708050
corresponding: 0.012903      2.014903
dynamic: 0.025806      2.708050
eagerly: 0.012903      2.708050
shows: 0.025806      1.609438
broken: 0.012903      2.708050
here: 0.006452      2.708050
define: 0.006452      2.708050
time: 0.032258      1.321756
CNTK,: 0.006452      2.708050
dramatically.: 0.006452      2.708050
We’ve: 0.006452      2.708050
C++-like: 0.006452      2.708050
motivations: 0.006452      2.708050
server: 0.032258      1.609438
wrap: 0.006452      2.708050
module.: 0.006452      2.708050
speedups: 0.006452      2.708050
top-end: 0.006452      2.708050
torch.autograd.: 0.006452      2.708050
we’d: 0.006452      2.708050
rendering,: 0.006452      2.708050
(besides: 0.006452      2.708050
loop: 0.025806      2.014903
local: 0.012903      2.014903
GPU,: 0.006452      2.708050
available.: 0.012903      2.014903
updating: 0.012903      2.014903
CUDA: 0.006452      2.708050
backend: 0.006452      2.708050
incurs: 0.006452      2.708050
issue: 0.006452      2.708050
access: 0.006452      2.708050
providers.: 0.006452      2.708050
notebooks: 0.006452      2.708050
Getting: 0.006452      2.708050
dependencies: 0.006452      2.708050
interactively.: 0.006452      2.708050
receive: 0.006452      2.708050
point,: 0.006452      2.708050
GitHub.: 0.006452      2.708050
How: 0.006452      2.708050
forums.7: 0.006452      2.708050
removing: 0.006452      2.708050
is: 0.316129      0.068993
into: 0.096774      0.628609
array: 0.006452      2.708050
similarities: 0.006452      2.708050
make: 0.012903      2.014903
project: 0.012903      2.014903
running,: 0.006452      2.708050
combination: 0.006452      2.708050
work.: 0.006452      2.708050
applications,: 0.006452      2.708050
foundational: 0.006452      2.708050
more: 0.077419      0.916291
things:: 0.006452      2.708050
punches: 0.006452      2.708050
tiny: 0.006452      2.708050
motivating: 0.006452      2.708050
image: 0.012903      2.014903
sets.: 0.012903      2.014903
pop: 0.006452      2.708050
practice,: 0.006452      2.708050
training: 0.109677      0.762140
times.: 0.006452      2.708050
uncertainty: 0.006452      2.708050
computation: 0.058065      1.098612
The: 0.154839      0.405465
unobtrusive;: 0.006452      2.708050
relied: 0.006452      2.708050
predict: 0.006452      2.708050
ones-versus-zeros: 0.006452      2.708050
pairs: 0.006452      2.708050
autonomously.: 0.006452      2.708050
change: 0.006452      2.708050
root: 0.012903      2.014903
specificity: 0.006452      2.708050
control:: 0.006452      2.708050
(Python: 0.006452      2.708050
differences: 0.006452      2.708050
terminology: 0.006452      2.708050
differ: 0.006452      2.708050
underlying: 0.012903      2.014903
single: 0.012903      2.014903
following: 0.006452      2.708050
assign: 0.006452      2.708050
(third: 0.006452      2.708050
nodes: 0.006452      2.708050
frameworks: 0.012903      2.014903
mode: 0.025806      2.014903
Note: 0.006452      2.708050
preceding: 0.006452      2.708050
nodes,: 0.006452      2.708050
1.0: 0.006452      2.708050
scripting: 0.006452      2.708050
wrappers: 0.006452      2.708050
Chainer,: 0.006452      2.708050
filled: 0.006452      2.708050
formalize: 0.006452      2.708050
it.: 0.012903      2.014903
solution: 0.006452      2.708050
parlance,: 0.006452      2.708050
(especially: 0.006452      2.708050
you’re: 0.012903      2.014903
GPU),: 0.006452      2.708050
call: 0.006452      2.708050
child: 0.006452      2.708050
resources: 0.006452      2.708050
cases,: 0.006452      2.708050
interpreter,: 0.006452      2.708050
instructions: 0.012903      2.708050
named: 0.006452      2.708050
TorchScript.: 0.006452      2.708050
CUDA-capable: 0.006452      2.708050
RAM: 0.012903      2.708050
better).: 0.006452      2.708050
That: 0.006452      2.708050
thanks: 0.006452      2.708050
Apple: 0.006452      2.708050
Windows-compatible: 0.006452      2.708050
convenience,: 0.006452      2.708050
heavy: 0.006452      2.708050
after: 0.006452      2.708050
generate: 0.006452      2.708050
website.6: 0.006452      2.708050
showing: 0.006452      2.708050
expressing: 0.006452      2.708050
experimentation: 0.006452      2.708050
building: 0.032258      1.321756
ease: 0.012903      2.014903
community,: 0.006452      2.708050
one: 0.025806      1.321756
with: 0.238710      0.068993
easy: 0.019355      2.014903
or: 0.116129      0.405465
present),: 0.006452      2.708050
practical: 0.012903      2.708050
engineers,: 0.006452      2.708050
disciplines: 0.006452      2.708050
To: 0.045161      0.762140
Python—We’re: 0.006452      2.708050
not: 0.032258      1.098612
smaller-scope: 0.006452      2.708050
2D: 0.006452      2.708050
enough: 0.006452      2.708050
they: 0.025806      1.321756
playing: 0.006452      2.708050
reasonable: 0.006452      2.708050
some: 0.032258      1.321756
its: 0.025806      1.609438
simplicity.: 0.006452      2.708050
familiar: 0.012903      2.708050
users: 0.012903      2.014903
back: 0.012903      2.014903
historical: 0.006452      2.708050
aims: 0.006452      2.708050
same: 0.038710      1.098612
directions.: 0.006452      2.708050
could: 0.019355      2.014903
enclosed: 0.006452      2.708050
finding: 0.006452      2.708050
isn’t: 0.012903      2.014903
ingest: 0.006452      2.708050
discovers: 0.006452      2.708050
together: 0.006452      2.708050
shown: 0.012903      2.014903
bottom: 0.006452      2.708050
inherently: 0.006452      2.708050
supporting: 0.006452      2.708050
Although: 0.012903      2.014903
analogies: 0.006452      2.708050
were: 0.012903      2.708050
Caffe,: 0.006452      2.708050
precursor: 0.006452      2.708050
mxnet,: 0.006452      2.708050
behind: 0.006452      2.708050
sufficient: 0.006452      2.708050
Flask: 0.006452      2.708050
web: 0.006452      2.708050
GPU.: 0.006452      2.708050
doesn’t: 0.012903      2.014903
natively: 0.006452      2.708050
simulation,: 0.006452      2.708050
layers,: 0.012903      2.708050
itself,: 0.006452      2.708050
loop):: 0.006452      2.708050
model.: 0.012903      2.014903
background: 0.006452      2.708050
contribute: 0.006452      2.708050
defaults: 0.006452      2.708050
adds: 0.006452      2.708050
Time: 0.006452      2.708050
personal: 0.012903      2.708050
small: 0.006452      2.708050
portion: 0.006452      2.708050
necessarily: 0.006452      2.708050
computer: 0.006452      2.708050
anticipate,: 0.006452      2.708050
less: 0.012903      2.014903
wait,: 0.006452      2.708050
seconds): 0.006452      2.708050
workstations: 0.006452      2.708050
offerings: 0.012903      2.708050
consideration:: 0.006452      2.708050
laptops: 0.006452      2.708050
itself: 0.006452      2.708050
notebook,: 0.006452      2.708050
mixing: 0.006452      2.708050
Introducing: 0.006452      2.708050
